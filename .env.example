# =============================================================================
# SOP LLM Service - Environment Configuration
# =============================================================================

# Application Settings
APP_NAME=SOP LLM Executor
APP_ENV=development
DEBUG=true
LOG_LEVEL=INFO

# Server Settings
SERVER_HOST=0.0.0.0
SERVER_PORT=8000

# =============================================================================
# Redis Cache & Queue
# =============================================================================
REDIS_URL=redis://redis:6379/1
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_DB=1
# REDIS_PASSWORD=optional_password

# Session & Task Settings
SESSION_TTL_SECONDS=3600
IDEMPOTENCY_TTL_SECONDS=86400
LOGS_MAX_RECENT=100

# =============================================================================
# LiteLLM Configuration (Production LLM Interface)
# =============================================================================

# LiteLLM Settings
LITELLM_DEBUG=false
LITELLM_DROP_PARAMS=true
LITELLM_MAX_RETRIES=3
LITELLM_TIMEOUT=600

# LLM Provider API Keys
# ----------------------
# Anthropic (Claude models)
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# OpenAI (GPT models)
OPENAI_API_KEY=your_openai_api_key_here

# Google Gemini
GEMINI_API_KEY=your_gemini_api_key_here

# Mistral AI
MISTRAL_API_KEY=your_mistral_api_key_here

# Cohere
COHERE_API_KEY=your_cohere_api_key_here

# =============================================================================
# Langfuse Observability (Production Tracing & Analytics)
# =============================================================================

LANGFUSE_ENABLED=true
LANGFUSE_PUBLIC_KEY=pk-lf-your-public-key
LANGFUSE_SECRET_KEY=sk-lf-your-secret-key
LANGFUSE_HOST=http://langfuse:3000

# Langfuse Server Configuration (for self-hosted setup)
LANGFUSE_NEXTAUTH_SECRET=change_this_to_random_string_min_32_chars
LANGFUSE_SALT=change_this_to_random_salt_min_32_chars

# =============================================================================
# Local Models Configuration
# =============================================================================

# GPU Settings
GPU_INDEX=0
MAX_VRAM_USAGE_PERCENT=90.0
VRAM_RESERVE_MB=512

# Model Paths
MODELS_DIR=./models
DEFAULT_CONTEXT_WINDOW=4096
DEFAULT_MAX_TOKENS=2048

# =============================================================================
# Webhook & HTTP Settings
# =============================================================================

WEBHOOK_TIMEOUT_SECONDS=30
WEBHOOK_MAX_RETRIES=3
HTTP_TIMEOUT_SECONDS=60
HTTP_MAX_RETRIES=2

# =============================================================================
# Advanced Features
# =============================================================================

# JSON Fixing (experimental)
ENABLE_JSON_FIXING=false
JSON_FIXER_TIMEOUT=30

# CORS
CORS_ALLOWED_ORIGINS=["*"]

# =============================================================================
# Kafka (Future Integration)
# =============================================================================
KAFKA_BOOTSTRAP_SERVERS=kafka:9092

# =============================================================================
# NOTES
# =============================================================================
#
# 1. PRODUCTION SECURITY:
#    - Change all passwords and secrets
#    - Use strong random values for LANGFUSE_NEXTAUTH_SECRET and LANGFUSE_SALT
#    - Never commit real API keys to git
#
# 2. LANGFUSE SETUP:
#    - Start Langfuse: cd .docker/containers/langfuse && docker-compose up -d
#    - Access UI: http://localhost:3000
#    - Create account and generate API keys
#    - Update LANGFUSE_PUBLIC_KEY and LANGFUSE_SECRET_KEY
#
# 3. LLM PROVIDERS:
#    - Only configure API keys for providers you use
#    - LiteLLM automatically detects provider from model name
#    - Supports 100+ providers out of the box
#
# 4. LOCAL MODELS:
#    - Place GGUF files in MODELS_DIR
#    - Register via API: POST /api/v1/models/register
#    - Requires CUDA-capable GPU
#
# =============================================================================

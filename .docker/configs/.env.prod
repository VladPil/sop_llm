# =============================================================================
# SOP LLM Service - Production Environment
# =============================================================================
# Для production deployment с максимальной производительностью
# Инфраструктура (Redis, Langfuse, etc.) запущена в sop_infrastructure
# =============================================================================

# =============================================================================
# Application Settings
# =============================================================================
APP_NAME=SOP LLM Service
APP_ENV=production
DEBUG=false
LOG_LEVEL=WARNING
LOG_FORMAT=json

# =============================================================================
# Server Settings
# =============================================================================
SERVER_HOST=0.0.0.0
SERVER_PORT=8000

# =============================================================================
# Service Ports (согласно PORT_MAPPING.md)
# =============================================================================
# sop_llm: блок 8200-8299
APP_PORT=8202      # Внешний порт API (localhost:8202)

# =============================================================================
# Redis Connection (Централизованная инфраструктура)
# =============================================================================
REDIS_HOST=${REDIS_HOST:-redis}
REDIS_PORT=${REDIS_PORT:-6379}
REDIS_DB=1  # Уникальная БД для sop_llm (0 для intake, 1 для llm, 2 для s3)
REDIS_PASSWORD=${REDIS_PASSWORD:-}
REDIS_URL=redis://${REDIS_HOST:-redis}:${REDIS_PORT:-6379}/1

# =============================================================================
# Kafka Connection (Централизованная инфраструктура)
# =============================================================================
KAFKA_BOOTSTRAP_SERVERS=${KAFKA_BOOTSTRAP_SERVERS:-kafka:9092}

# Redis Session Settings
SESSION_TTL_SECONDS=3600
IDEMPOTENCY_TTL_SECONDS=86400
LOGS_MAX_RECENT=100

# =============================================================================
# LLM Settings
# =============================================================================
MODELS_DIR=/app/models
DEFAULT_CONTEXT_WINDOW=4096
DEFAULT_MAX_TOKENS=2048

# =============================================================================
# Langfuse Observability (Централизованная инфраструктура)
# =============================================================================
LANGFUSE_ENABLED=true
LANGFUSE_PUBLIC_KEY=${LANGFUSE_PUBLIC_KEY}
LANGFUSE_SECRET_KEY=${LANGFUSE_SECRET_KEY}
LANGFUSE_HOST=${LANGFUSE_HOST:-http://langfuse:3000}

# =============================================================================
# LiteLLM Configuration
# =============================================================================
LITELLM_DEBUG=false
LITELLM_DROP_PARAMS=true
LITELLM_MAX_RETRIES=5
LITELLM_TIMEOUT=600

# =============================================================================
# External LLM Provider API Keys
# =============================================================================
# ВАЖНО: В production все API ключи должны передаваться через секреты!

# OpenAI (GPT models)
OPENAI_API_KEY=${OPENAI_API_KEY}
OPENAI_BASE_URL=${OPENAI_BASE_URL:-}

# Anthropic (Claude models)
ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}

# OpenAI-Compatible (Ollama, LocalAI, etc.)
OPENAI_COMPATIBLE_BASE_URL=${OPENAI_COMPATIBLE_BASE_URL:-}
OPENAI_COMPATIBLE_API_KEY=${OPENAI_COMPATIBLE_API_KEY:-}

# Google Gemini
GEMINI_API_KEY=${GEMINI_API_KEY:-}

# Mistral AI
MISTRAL_API_KEY=${MISTRAL_API_KEY:-}

# HuggingFace (для загрузки моделей)
HUGGINGFACE_TOKEN=${HUGGINGFACE_TOKEN}

# =============================================================================
# GPU Settings (Local Models)
# =============================================================================
# Production окружение с GPU для высокопроизводительных локальных моделей
INSTALL_GPU=true
CUDA_VERSION=12.1.0
DEVICE=cuda

GPU_INDEX=0
MAX_VRAM_USAGE_PERCENT=80.0
VRAM_RESERVE_MB=1024

# GPU Environment Variables
NVIDIA_VISIBLE_DEVICES=all
NVIDIA_DRIVER_CAPABILITIES=compute,utility

# =============================================================================
# HTTP Settings
# =============================================================================
WEBHOOK_TIMEOUT_SECONDS=60
WEBHOOK_MAX_RETRIES=5
HTTP_TIMEOUT_SECONDS=120
HTTP_MAX_RETRIES=3

# =============================================================================
# CORS Settings
# =============================================================================
# В production указывать конкретные домены!
CORS_ALLOWED_ORIGINS=["https://app.example.com"]

# =============================================================================
# Performance Settings (Production Optimized)
# =============================================================================
WORKERS=4
THREADS=16
TORCH_NUM_THREADS=16
OMP_NUM_THREADS=16

# =============================================================================
# Feature Flags
# =============================================================================
ENABLE_JSON_FIXING=true
JSON_FIXER_TIMEOUT=90

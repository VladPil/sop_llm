# Пресеты облачных моделей
#
# Поля точно маппятся в LiteLLMProvider (src/providers/litellm_provider.py):
# - provider_config.model_name -> LiteLLMProvider.model_name
# - provider_config.api_key -> LiteLLMProvider.api_key (или из env)
# - provider_config.base_url -> LiteLLMProvider.base_url
# - provider_config.timeout -> LiteLLMProvider.timeout
# - provider_config.max_retries -> LiteLLMProvider.max_retries
#
# api_key_env_var указывает имя environment variable с API ключом.
# Ключ берётся из env если provider_config.api_key не указан.

models:
  # === Anthropic Claude ===

  - name: "claude-sonnet-4"
    provider: "anthropic"
    api_key_env_var: "ANTHROPIC_API_KEY"
    provider_config:
      model_name: "claude-sonnet-4-20250514"
      timeout: 600
      max_retries: 3

  - name: "claude-3.5-haiku"
    provider: "anthropic"
    api_key_env_var: "ANTHROPIC_API_KEY"
    provider_config:
      model_name: "claude-3-5-haiku-20241022"
      timeout: 300
      max_retries: 3

  - name: "claude-3-opus"
    provider: "anthropic"
    api_key_env_var: "ANTHROPIC_API_KEY"
    provider_config:
      model_name: "claude-3-opus-20240229"
      timeout: 900
      max_retries: 3

  # === OpenAI GPT ===

  - name: "gpt-4-turbo"
    provider: "openai"
    api_key_env_var: "OPENAI_API_KEY"
    provider_config:
      model_name: "gpt-4-turbo"
      timeout: 600
      max_retries: 3

  - name: "gpt-4o"
    provider: "openai"
    api_key_env_var: "OPENAI_API_KEY"
    provider_config:
      model_name: "gpt-4o"
      timeout: 600
      max_retries: 3

  - name: "gpt-4o-mini"
    provider: "openai"
    api_key_env_var: "OPENAI_API_KEY"
    provider_config:
      model_name: "gpt-4o-mini"
      timeout: 300
      max_retries: 3

  - name: "gpt-3.5-turbo"
    provider: "openai"
    api_key_env_var: "OPENAI_API_KEY"
    provider_config:
      model_name: "gpt-3.5-turbo"
      timeout: 300
      max_retries: 3

  - name: "o1-preview"
    provider: "openai"
    api_key_env_var: "OPENAI_API_KEY"
    provider_config:
      model_name: "o1-preview"
      timeout: 900
      max_retries: 3

  - name: "o1-mini"
    provider: "openai"
    api_key_env_var: "OPENAI_API_KEY"
    provider_config:
      model_name: "o1-mini"
      timeout: 600
      max_retries: 3

  # === Google Gemini (через LiteLLM) ===

  - name: "gemini-1.5-pro"
    provider: "openai_compatible"
    api_key_env_var: "GOOGLE_API_KEY"
    provider_config:
      model_name: "gemini/gemini-1.5-pro"
      timeout: 600
      max_retries: 3

  - name: "gemini-1.5-flash"
    provider: "openai_compatible"
    api_key_env_var: "GOOGLE_API_KEY"
    provider_config:
      model_name: "gemini/gemini-1.5-flash"
      timeout: 300
      max_retries: 3

  # === Mistral AI ===

  - name: "mistral-large"
    provider: "openai_compatible"
    api_key_env_var: "MISTRAL_API_KEY"
    provider_config:
      model_name: "mistral/mistral-large-latest"
      timeout: 600
      max_retries: 3

  - name: "mistral-medium"
    provider: "openai_compatible"
    api_key_env_var: "MISTRAL_API_KEY"
    provider_config:
      model_name: "mistral/mistral-medium-latest"
      timeout: 300
      max_retries: 3

  # === Groq (быстрый inference) ===

  - name: "groq-llama-3.1-70b"
    provider: "openai_compatible"
    api_key_env_var: "GROQ_API_KEY"
    provider_config:
      model_name: "groq/llama-3.1-70b-versatile"
      timeout: 120
      max_retries: 3

  - name: "groq-mixtral-8x7b"
    provider: "openai_compatible"
    api_key_env_var: "GROQ_API_KEY"
    provider_config:
      model_name: "groq/mixtral-8x7b-32768"
      timeout: 120
      max_retries: 3

  # === Together AI ===

  - name: "together-llama-3.1-405b"
    provider: "openai_compatible"
    api_key_env_var: "TOGETHER_API_KEY"
    provider_config:
      model_name: "together_ai/meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo"
      timeout: 600
      max_retries: 3

  # === DeepSeek ===

  - name: "deepseek-coder"
    provider: "openai_compatible"
    api_key_env_var: "DEEPSEEK_API_KEY"
    provider_config:
      model_name: "deepseek/deepseek-coder"
      timeout: 300
      max_retries: 3

  - name: "deepseek-chat"
    provider: "openai_compatible"
    api_key_env_var: "DEEPSEEK_API_KEY"
    provider_config:
      model_name: "deepseek/deepseek-chat"
      timeout: 300
      max_retries: 3

  # =============================================================================
  # Ollama (локальные GPU модели через LiteLLM)
  # =============================================================================
  # Ollama автоматически скачивает модели при первом использовании.
  # Требуется запущенный Ollama сервер (docker-compose.gpu.yml)
  # Документация: https://docs.litellm.ai/docs/providers/ollama
  #
  # keep_alive: время удержания модели в VRAM
  #   - "5m" (default) - 5 минут
  #   - "1h" - 1 час
  #   - "-1" - бесконечно (не выгружать)
  #   - "0" - выгрузить сразу после запроса

  # === Qwen 2.5 Series ===

  - name: "qwen2.5:3b"
    provider: "ollama"
    description: "Qwen 2.5 3B - компактная модель для простых задач (GPU)"
    provider_config:
      model_name: "ollama/qwen2.5:3b"
      timeout: 300
      max_retries: 2
      keep_alive: "30m"

  - name: "qwen2.5:7b"
    provider: "ollama"
    description: "Qwen 2.5 7B - универсальная модель (GPU)"
    provider_config:
      model_name: "ollama/qwen2.5:7b"
      timeout: 300
      max_retries: 2
      keep_alive: "30m"

  - name: "qwen2.5:14b"
    provider: "ollama"
    description: "Qwen 2.5 14B - мощная модель для сложных задач (GPU)"
    provider_config:
      model_name: "ollama/qwen2.5:14b"
      timeout: 600
      max_retries: 2
      keep_alive: "30m"

  - name: "qwen2.5-coder:7b"
    provider: "ollama"
    description: "Qwen 2.5 Coder 7B - специализированная модель для кода (GPU)"
    provider_config:
      model_name: "ollama/qwen2.5-coder:7b"
      timeout: 300
      max_retries: 2
      keep_alive: "30m"

  # === LLaMA Series ===

  - name: "llama3.2:3b"
    provider: "ollama"
    description: "LLaMA 3.2 3B - быстрая модель от Meta (GPU)"
    provider_config:
      model_name: "ollama/llama3.2:3b"
      timeout: 300
      max_retries: 2
      keep_alive: "30m"

  - name: "llama3.1:8b"
    provider: "ollama"
    description: "LLaMA 3.1 8B - универсальная модель от Meta (GPU)"
    provider_config:
      model_name: "ollama/llama3.1:8b"
      timeout: 300
      max_retries: 2
      keep_alive: "30m"

  # === Mistral Series ===

  - name: "mistral:7b"
    provider: "ollama"
    description: "Mistral 7B - эффективная модель (GPU)"
    provider_config:
      model_name: "ollama/mistral:7b"
      timeout: 300
      max_retries: 2
      keep_alive: "30m"

  # === Gemma Series ===

  - name: "gemma2:9b"
    provider: "ollama"
    description: "Gemma 2 9B - модель от Google (GPU)"
    provider_config:
      model_name: "ollama/gemma2:9b"
      timeout: 300
      max_retries: 2
      keep_alive: "30m"

  # === DeepSeek Coder Local ===

  - name: "deepseek-coder-v2:16b"
    provider: "ollama"
    description: "DeepSeek Coder V2 16B - мощная модель для кода (GPU)"
    provider_config:
      model_name: "ollama/deepseek-coder-v2:16b"
      timeout: 600
      max_retries: 2
      keep_alive: "30m"

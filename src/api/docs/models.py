"""Documentation strings для Models API."""

LIST_MODELS = """
Возвращает список всех активных (созданных) моделей в системе.

## Lazy Loading

С версии 1.0 используется lazy loading — модели создаются автоматически
при первом обращении. Этот endpoint показывает только уже активированные модели.

**Для просмотра всех доступных моделей используйте** `GET /models/presets`

## Что возвращает

Для каждой активной модели:
- **name** — уникальное имя модели (используется в запросах генерации)
- **provider** — тип провайдера (`litellm`, `local`)
- **context_window** — максимальный размер контекста в токенах
- **max_output_tokens** — максимальное количество токенов в ответе
- **supports_streaming** — поддержка потоковой генерации
- **supports_structured_output** — поддержка JSON Schema
- **loaded** — статус загрузки

## Типы провайдеров

| Провайдер | Описание |
|-----------|----------|
| `litellm` | Унифицированный доступ к 100+ API (OpenAI, Anthropic, Ollama и др.) |
| `local` | Локальные embedding модели через SentenceTransformers |
"""

GET_MODEL_INFO = """
Возвращает информацию о модели с автоматической активацией (lazy loading).

## Lazy Loading

При обращении к модели, которая ещё не была активирована, система автоматически:
1. Находит пресет модели в конфигурации
2. Создаёт провайдер с нужными параметрами
3. Возвращает информацию о модели

## Параметры

- **model_name** (path) — имя модели из пресетов (см. `GET /models/presets`)

## Что возвращает

- **name** — имя модели
- **provider** — тип провайдера (`litellm`)
- **context_window** — размер контекстного окна (в токенах)
- **max_output_tokens** — максимум токенов в ответе
- **supports_streaming** — поддержка потоковой генерации
- **supports_structured_output** — поддержка JSON Schema
- **loaded** — всегда `true` (модель активирована)
- **extra** — дополнительные метаданные

## Ошибки

- **404 Not Found** — модель не найдена в пресетах
"""

UNREGISTER_MODEL = """
Удаляет активную модель из системы (освобождает ресурсы).

## Что происходит при удалении

1. Модель удаляется из активных провайдеров
2. Если `cleanup=true` (по умолчанию):
   - Закрываются HTTP соединения
   - Освобождаются связанные ресурсы

## Параметры

| Параметр | Тип | Описание |
|----------|-----|----------|
| `model_name` | path | Имя активной модели |
| `cleanup` | query | Выполнить очистку ресурсов (default: true) |

## Lazy Loading

После удаления модель может быть автоматически активирована снова
при следующем запросе к ней.

## Ошибки

- **404 Not Found** — модель не активирована (не найдена среди активных)
"""

LIST_PRESETS = """
Возвращает список всех доступных моделей из конфигурационных файлов.

## Lazy Loading

Модели из пресетов активируются автоматически при первом использовании.
Ручная регистрация НЕ требуется.

## Типы пресетов

### Облачные модели (cloud_models)
API провайдеры через LiteLLM (требуют API ключи):
- **Anthropic**: Claude 3.5 Sonnet/Haiku, Claude 3 Opus
- **OpenAI**: GPT-4 Turbo, GPT-4o, GPT-4o-mini
- **Google**: Gemini Pro
- **Ollama**: Локальные GPU модели (llama3, qwen2.5 и др.)
- **Groq, Together AI, DeepSeek** и другие

### Локальные модели (local_models)
GGUF модели для запуска на GPU через llama.cpp:
- Qwen 2.5 (3B, 7B, 14B)
- LLaMA 3.2 (3B, 8B)
- Mistral 7B, Phi-3

### Embedding модели (embedding_models)
Модели для векторизации текста:
- multilingual-e5-large
- all-MiniLM-L6-v2
- BGE, Cohere, Jina

## Использование

1. Получите список пресетов через этот endpoint
2. Используйте `name` модели в запросах генерации (`POST /tasks`)
3. Модель автоматически активируется при первом запросе
"""

CHECK_COMPATIBILITY = """
Проверяет, поместится ли локальная модель в доступную видеопамять (VRAM).

## Зачем это нужно

Локальные GGUF модели требуют значительного объёма VRAM для работы.
Этот endpoint позволяет заранее проверить:
- Поместится ли модель в доступную VRAM
- Какую квантизацию лучше использовать
- Сколько памяти потребуется

## Как работает

1. Получает требования VRAM из пресета модели
2. Запрашивает текущую доступную VRAM у GPU
3. Сравнивает и выдаёт рекомендацию

## Параметры запроса

| Параметр | Тип | Описание |
|----------|-----|----------|
| `preset_name` | string | Имя локального пресета |
| `quantization` | string | Квантизация для проверки (опционально) |

## Квантизации

| Квантизация | Размер | Качество | Пример для 7B модели |
|-------------|--------|----------|---------------------|
| `q4_k_m` | ~50% | Хорошее | ~4-5 GB |
| `q5_k_m` | ~60% | Очень хорошее | ~5-6 GB |
| `q8_0` | ~90% | Отличное | ~8-9 GB |
| `fp16` | 100% | Максимальное | ~14 GB |

## Что возвращает

| Поле | Описание |
|------|----------|
| `compatible` | Поместится ли модель в VRAM |
| `required_vram_mb` | Требуемая VRAM в MB |
| `available_vram_mb` | Доступная VRAM в MB |
| `recommended_quantization` | Рекомендуемая квантизация (если не compatible) |
| `warning` | Предупреждение о нехватке памяти |

## Примечание

Проверка выполняется только для **локальных** моделей.
Облачные модели не требуют локальных ресурсов GPU.
"""
